{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### *** French lemmatization and synsets with spacy and nltk *** ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " OTTAWA | La ministre canadienne des Affaires étrangères, Chrystia Freeland, qui a reçu une délégation du gouvernement mexicain, a estimé mardi que les droits de douane américains sur l'aluminium et l'acier devaient être «abolis» pour «un vrai libre-échange» en Amérique du Nord.\n"
     ]
    }
   ],
   "source": [
    "### *** Lemmatization *** ### \n",
    "\n",
    "# Note the wordnet included in the nltk corpus already includes French\n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import wordnet as wn \n",
    "\n",
    "# Example political text taken from \n",
    "# https://www.journaldemontreal.com/2019/05/14/front-commun-canada-mexique-contre-les-droits-de-douane-americains-1\n",
    "\n",
    "text = \"\"\" OTTAWA | La ministre canadienne des Affaires étrangères, Chrystia Freeland, qui a reçu une délégation du gouvernement mexicain, a estimé mardi que les droits de douane américains sur l'aluminium et l'acier devaient être «abolis» pour «un vrai libre-échange» en Amérique du Nord.\"\"\"\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***nltk tokenization*** \n",
      "\n",
      "['Chaque', 'jour', ',', 'les', 'sans-papiers', 'franchissent', 'par', 'centaines', ',', 'parfois', 'par', 'milliers', ',', 'le', 'fleuve', 'Suchiate', ',', 'qui', 'sépare', 'le', 'Guatemala', 'du', 'Mexique', '.', 'Leur', 'nombre', 'est', 'évalué', 'à', 'plus', 'de', '300', '000', 'lors', 'du', 'premier', 'trimestre', '2019', 'par', 'l', '’', 'Institut', 'national', 'mexicain', 'des', 'migrations', '(', 'INM', ')', ',', 'soit', 'trois', 'à', 'quatre', 'fois', 'plus', 'que', 'les', 'années', 'précédentes', '.', 'Du', 'jamais-vu', 'lié', 'au', 'nouveau', 'phénomène', 'des', 'caravanes', 'de', 'Centraméricains', ',', 'fuyant', 'ensemble', 'la', 'misère', 'et', 'la', 'violence', 'de', 'leurs', 'pays', 'd', '’', 'origine', '.', 'Ce', 'tsunami', 'migratoire', 'provoque', 'des', 'goulots', 'd', '’', 'étranglement', '.', 'A', 'Tapachula', ',', 'principale', 'ville', 'frontalière', 'avec', 'le', 'Guatemala', ',', 'les', 'clandestins', 'attendent', 'en', 'masse', 'des', 'permis', 'de', 'transit', 'pour', 'continuer', 'leur', 'route', 'vers', 'les', 'Etats-Unis', '.'] \n",
      "\n",
      "['Chaque jour, les sans-papiers franchissent par centaines, parfois par milliers, le fleuve Suchiate, qui sépare le Guatemala du Mexique.', 'Leur nombre est évalué à plus de 300 000 lors du premier trimestre 2019 par l’Institut national mexicain des migrations (INM), soit trois à quatre fois plus que les années précédentes.', 'Du jamais-vu lié au nouveau phénomène des caravanes de Centraméricains, fuyant ensemble la misère et la violence de leurs pays d’origine.', 'Ce tsunami migratoire provoque des goulots d’étranglement.', 'A Tapachula, principale ville frontalière avec le Guatemala, les clandestins attendent en masse des permis de transit pour continuer leur route vers les Etats-Unis.'] \n",
      "\n",
      "***spacy tokenization*** \n",
      "\n",
      "['Chaque', 'jour', 'les', 'franchissent', 'par', 'centaines', 'parfois', 'par', 'milliers', 'le', 'fleuve', 'Suchiate', 'qui', 'sépare', 'le', 'Guatemala', 'du', 'Mexique', 'Leur', 'nombre', 'est', 'évalué', 'à', 'plus', 'de', 'lors', 'du', 'premier', 'trimestre', 'par', 'Institut', 'national', 'mexicain', 'des', 'migrations', 'INM', 'soit', 'trois', 'à', 'quatre', 'fois', 'plus', 'que', 'les', 'années', 'précédentes', 'Du', 'jamais', 'vu', 'lié', 'au', 'nouveau', 'phénomène', 'des', 'caravanes', 'de', 'Centraméricains', 'fuyant', 'ensemble', 'la', 'misère', 'et', 'la', 'violence', 'de', 'leurs', 'pays', 'origine', 'Ce', 'tsunami', 'migratoire', 'provoque', 'des', 'goulots', 'étranglement', 'A', 'Tapachula', 'principale', 'ville', 'frontalière', 'avec', 'le', 'Guatemala', 'les', 'clandestins', 'attendent', 'en', 'masse', 'des', 'permis', 'de', 'transit', 'pour', 'continuer', 'leur', 'route', 'vers', 'les'] \n",
      "\n",
      "[Chaque jour, les sans-papiers franchissent par centaines, parfois par milliers, le fleuve Suchiate, qui sépare le Guatemala du Mexique., Leur nombre est évalué à plus de 300 000 lors du premier trimestre 2019 par l’Institut national mexicain des migrations (INM), soit trois à quatre fois plus que les années précédentes., Du jamais-vu lié au nouveau phénomène des caravanes de Centraméricains, fuyant ensemble la misère et la violence de leurs pays d’origine., Ce tsunami migratoire provoque des goulots d’étranglement., A Tapachula, principale ville frontalière avec le Guatemala, les clandestins attendent en masse des permis de transit pour continuer leur route vers les Etats-Unis.] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Comments: \\n    spacy also does the job '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Tokenization ###\n",
    "\n",
    "## nltk ## \n",
    "print(\"***nltk tokenization*** \\n\")\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "word_tokens = [token for token in word_tokenize(text, language='french')] # tokenize by words\n",
    "sent_tokens = [sent for sent in sent_tokenize(text, language='french')] # tokenize by sentence\n",
    "print(word_tokens, \"\\n\") \n",
    "print(sent_tokens, \"\\n\")\n",
    "\n",
    "\"\"\"Comments: \n",
    "    nltk seems to do the job just right.\"\"\"\n",
    "\n",
    "## spacy ## \n",
    "\n",
    "print(\"***spacy tokenization*** \\n\")\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "# NOTE: A more comprehensive model is available: fr_core_news_md\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "sp_word_tokens = [token.text for token in doc if token.text.isalpha()]\n",
    "sp_sent_tokens = [sent for sent in doc.sents]\n",
    "print(sp_word_tokens, \"\\n\")\n",
    "print(sp_sent_tokens, \"\\n\")\n",
    "\n",
    "\"\"\" Comments: \n",
    "    spacy also does the job \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**nltk lemmatization***\n",
      "\n",
      "[('OTTAWA', 'ottaw'), ('La', 'la'), ('ministre', 'ministr'), ('canadienne', 'canadien'), ('des', 'de'), ('Affaires', 'affair'), ('étrangères', 'étranger'), ('Chrystia', 'chrysti'), ('Freeland', 'freeland'), ('qui', 'qui'), ('a', 'a'), ('reçu', 'reçu'), ('une', 'une'), ('délégation', 'déleg'), ('du', 'du'), ('gouvernement', 'gouvern'), ('mexicain', 'mexicain'), ('a', 'a'), ('estimé', 'estim'), ('mardi', 'mard'), ('que', 'que'), ('les', 'le'), ('droits', 'droit'), ('de', 'de'), ('douane', 'douan'), ('américains', 'américain'), ('sur', 'sur'), ('et', 'et'), ('devaient', 'dev'), ('être', 'être'), ('abolis', 'abol'), ('pour', 'pour'), ('un', 'un'), ('vrai', 'vrai'), ('en', 'en'), ('Amérique', 'amer'), ('du', 'du'), ('Nord', 'nord')] \n",
      "\n",
      "***spacy lemmatization***\n",
      "\n",
      "[('OTTAWA', 'ottawa'), ('La', 'le'), ('ministre', 'ministre'), ('canadienne', 'canadien'), ('des', 'un'), ('Affaires', 'affaire'), ('étrangères', 'étranger'), ('Chrystia', 'Chrystia'), ('Freeland', 'Freeland'), ('qui', 'qui'), ('a', 'avoir'), ('reçu', 'recevoir'), ('une', 'un'), ('délégation', 'délégation'), ('du', 'du'), ('gouvernement', 'gouvernement'), ('mexicain', 'mexicain'), ('a', 'avoir'), ('estimé', 'estimer'), ('mardi', 'mardi'), ('que', 'que'), ('les', 'le'), ('droits', 'droit'), ('de', 'de'), ('douane', 'douan'), ('américains', 'américain'), ('sur', 'sur'), ('aluminium', 'aluminium'), ('et', 'et'), ('acier', 'acier'), ('devaient', 'devoir'), ('être', 'être'), ('abolis', 'abolir'), ('pour', 'pour'), ('un', 'un'), ('vrai', 'vrai'), ('en', 'en'), ('Amérique', 'Amérique'), ('du', 'du'), ('Nord', 'nord')]\n",
      "Lemma:  ottawa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Comments: \\n    - Compared to nltk, spacy does an amazing job in lemmatizing French. '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization ### \n",
    "\n",
    "## nltk ##\n",
    "print(\"**nltk lemmatization***\\n\")\n",
    "\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "\n",
    "stemmer = FrenchStemmer() # instantiate the stemmer \n",
    "\n",
    "alpha_words = [w for w in word_tokens if w.isalpha()] # remove punctuation\n",
    "nltk_fr_stems = [(word, stemmer.stem(word)) for word in alpha_words]\n",
    "\n",
    "print(nltk_fr_stems, \"\\n\") \n",
    "\n",
    "\"\"\" Comments: \n",
    "    - As it can be seen, nltk does a very poor job in lemmatizing French.\n",
    "    - An alternative could be to implement our own stemmer with the \n",
    "        stem.Regexp() function, but it looks quite time consuming, \n",
    "        given all the irregularities of the language. In fact, implementing \n",
    "        a new module would be a better idea.\"\"\"\n",
    "\n",
    "## spacy lemmatization: ##\n",
    "print(\"***spacy lemmatization***\\n\")\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "doc = nlp(text)\n",
    "doc_lemmas = [(token.text, token.lemma_) for token in doc if token.text.isalpha()]\n",
    "print(doc_lemmas)\n",
    "\n",
    "print(\"Lemma: \", doc_lemmas[0][1])\n",
    "\"\"\" Comments: \n",
    "    - Compared to nltk, spacy does an amazing job in lemmatizing French. \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***nltk synsets***\n",
      "\n",
      "word : OTTAWA\n",
      "[Synset('ottawa.n.03'), Synset('ottawa.n.01')]\n",
      "\n",
      "word : La\n",
      "[Synset('statistics.n.01'), Synset('statistics.n.01'), Synset('ladyship.n.01'), Synset('la.n.03'), Synset('la.n.03'), Synset('louisiana.n.01'), Synset('lanthanum.n.01'), Synset('lanthanum.n.01'), Synset('lanthanum.n.01')]\n",
      "\n",
      "word : ministre\n",
      "[Synset('minister.n.04'), Synset('indigo_bunting.n.01'), Synset('minister.v.02'), Synset('minister.v.01'), Synset('curate.n.01'), Synset('minister.n.03'), Synset('minister.n.02')]\n",
      "\n",
      "word : canadienne\n",
      "[]\n",
      "\n",
      "word : des\n",
      "[]\n",
      "\n",
      "word : Affaires\n",
      "[]\n",
      "\n",
      "word : étrangères\n",
      "[]\n",
      "\n",
      "word : Chrystia\n",
      "[]\n",
      "\n",
      "word : Freeland\n",
      "[]\n",
      "\n",
      "word : qui\n",
      "[Synset('world_health_organization.n.01')]\n",
      "\n",
      "\n",
      "***spacy + nltk synsets***\n",
      "\n",
      "word : OTTAWA\n",
      "[Synset('ottawa.n.03'), Synset('ottawa.n.01')]\n",
      "\n",
      "word : La\n",
      "[Synset('lordship.n.02'), Synset('lordship.n.01'), Synset('lupus_erythematosus.n.01')]\n",
      "\n",
      "word : ministre\n",
      "[Synset('minister.n.04'), Synset('indigo_bunting.n.01'), Synset('minister.v.02'), Synset('minister.v.01'), Synset('curate.n.01'), Synset('minister.n.03'), Synset('minister.n.02')]\n",
      "\n",
      "word : canadienne\n",
      "[Synset('canadian.a.01'), Synset('canadian.n.02'), Synset('canadian.n.01'), Synset('french_canadian.n.01')]\n",
      "\n",
      "word : des\n",
      "[Synset('matchless.s.01'), Synset('one.s.05'), Synset('one.s.06'), Synset('one.s.04'), Synset('one.s.01'), Synset('one.s.01'), Synset('two.s.01'), Synset('three.s.01'), Synset('one.s.02'), Synset('one.n.02'), Synset('associate_in_nursing.n.01'), Synset('one.n.01'), Synset('one.n.01'), Synset('three.n.01'), Synset('sunday.n.01')]\n",
      "\n",
      "word : Affaires\n",
      "[Synset('matter.n.01'), Synset('business.n.04'), Synset('things.n.01'), Synset('case.n.12')]\n",
      "\n",
      "word : étrangères\n",
      "[Synset('foreign.a.02'), Synset('alien.s.02'), Synset('foreign.a.01'), Synset('alien.s.01'), Synset('estrange.v.02'), Synset('extraneous.s.03'), Synset('alien.v.01'), Synset('extraterrestrial_being.n.01'), Synset('foreigner.n.01'), Synset('foreigner.n.02'), Synset('stranger.n.01')]\n",
      "\n",
      "word : Chrystia\n",
      "[]\n",
      "\n",
      "word : Freeland\n",
      "[]\n",
      "\n",
      "word : qui\n",
      "[Synset('world_health_organization.n.01')]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Comments: \\n    - Better results but several entries are obviously wrong. \\n    - We could filter things like articles and propositions since finding synsets for these \\n        might not be very useful. '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Synsets ### \n",
    "\n",
    "## nltk ##\n",
    "\n",
    "print(\"***nltk synsets***\\n\")\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Note I decided to use alpha words and not stemmed given that the nltk stemmed words for \n",
    "# French are so imprecise. The result would be a bunch of empty synsets. \n",
    "\n",
    "# create a dictionary of synsets for each word\n",
    "nltk_synsets_fr = {word: wn.synsets(word, lang='fra') for word in alpha_words}\n",
    "\n",
    "def print_synsets(synset, num_synsets=10):\n",
    "    \"\"\" expects a dictionary with synsets. \n",
    "        prints num_synsets number of synsets in the dictionary\"\"\"\n",
    "    i = 0\n",
    "    for key, val in synset.items():\n",
    "        if i < num_synsets: \n",
    "            print(\"word : {}\".format(key))\n",
    "            print(val)\n",
    "            i += 1\n",
    "            print()\n",
    "    \n",
    "print_synsets(nltk_synsets_fr)\n",
    "\n",
    "\"\"\" Comments: \n",
    "    Many words are missing synsets. \"\"\"\n",
    "\n",
    "## spacy + nltk ##\n",
    "\n",
    "print(\"\\n***spacy + nltk synsets***\\n\")\n",
    "\n",
    "spnlkt_synsest_fr = {tup[0]: wn.synsets(tup[1], lang='fra') for tup in doc_lemmas}\n",
    "\n",
    "print_synsets(spnlkt_synsest_fr) \n",
    "\n",
    "\"\"\" Comments: \n",
    "    - Better results but several entries are obviously wrong. \n",
    "    - We could filter things like articles and propositions since finding synsets for these \n",
    "        might not be very useful. \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***improved spacy+nltk***\n",
      "\n",
      "**filtered doc lemmas**\n",
      "\n",
      "[('OTTAWA', 'ottawa'), ('ministre', 'ministre'), ('canadienne', 'canadien'), ('Affaires', 'affaire'), ('étrangères', 'étranger'), ('Chrystia', 'Chrystia'), ('Freeland', 'Freeland'), ('qui', 'qui'), ('a', 'avoir'), ('reçu', 'recevoir'), ('délégation', 'délégation'), ('gouvernement', 'gouvernement'), ('mexicain', 'mexicain'), ('a', 'avoir'), ('estimé', 'estimer'), ('mardi', 'mardi'), ('que', 'que'), ('droits', 'droit'), ('douane', 'douan'), ('américains', 'américain'), ('aluminium', 'aluminium'), ('acier', 'acier'), ('devaient', 'devoir'), ('être', 'être'), ('abolis', 'abolir'), ('vrai', 'vrai'), ('Amérique', 'Amérique'), ('Nord', 'nord')]\n",
      "\n",
      "**synsets**\n",
      "\n",
      "word : ottawa\n",
      "[Synset('ottawa.n.03'), Synset('ottawa.n.01')]\n",
      "\n",
      "word : ministre\n",
      "[Synset('minister.n.04'), Synset('indigo_bunting.n.01'), Synset('minister.v.02'), Synset('minister.v.01'), Synset('curate.n.01'), Synset('minister.n.03'), Synset('minister.n.02')]\n",
      "\n",
      "word : canadien\n",
      "[Synset('canadian.a.01'), Synset('canadian.n.02'), Synset('canadian.n.01'), Synset('french_canadian.n.01')]\n",
      "\n",
      "word : affaire\n",
      "[Synset('matter.n.01'), Synset('business.n.04'), Synset('things.n.01'), Synset('case.n.12')]\n",
      "\n",
      "word : étranger\n",
      "[Synset('foreign.a.02'), Synset('alien.s.02'), Synset('foreign.a.01'), Synset('alien.s.01'), Synset('estrange.v.02'), Synset('extraneous.s.03'), Synset('alien.v.01'), Synset('extraterrestrial_being.n.01'), Synset('foreigner.n.01'), Synset('foreigner.n.02'), Synset('stranger.n.01')]\n",
      "\n",
      "word : Chrystia\n",
      "[]\n",
      "\n",
      "word : Freeland\n",
      "[]\n",
      "\n",
      "word : qui\n",
      "[Synset('world_health_organization.n.01')]\n",
      "\n",
      "word : avoir\n",
      "[Synset('beget.v.01'), Synset('give_birth.v.01'), Synset('have.v.12'), Synset('suffer.v.02'), Synset('contract.v.04'), Synset('grow.v.08'), Synset('get.v.03'), Synset('have.v.11'), Synset('receive.v.02'), Synset('catch.v.18'), Synset('get.v.20'), Synset('interview.v.01'), Synset('interview.v.03'), Synset('retention.n.01'), Synset('old.s.07'), Synset('deceive.v.02'), Synset('old.s.03'), Synset('drive.v.11'), Synset('get.v.14'), Synset('honest-to-god.s.01'), Synset('sleep_together.v.01'), Synset('take.v.35'), Synset('bring.v.04'), Synset('old.a.02'), Synset('draw.v.15'), Synset('old.a.01'), Synset('hold.v.03'), Synset('catch.v.24'), Synset('get.v.27'), Synset('scram.v.01'), Synset('experience.v.03'), Synset('have.v.01'), Synset('own.v.01'), Synset('have.v.09'), Synset('get.v.22'), Synset('receive.v.01'), Synset('accept.v.02'), Synset('obtain.v.01'), Synset('have.v.17'), Synset('get.v.21'), Synset('have.v.07'), Synset('deceive.v.01'), Synset('flim-flam.v.01'), Synset('have.v.02'), Synset('carry.v.21'), Synset('prevail.v.02'), Synset('embody.v.02'), Synset('carry.v.02'), Synset('have.v.10'), Synset('be.v.12'), Synset('carry.v.18'), Synset('minister.n.03'), Synset('rich_person.n.01'), Synset('property.n.01'), Synset('credit_side.n.01')]\n",
      "\n",
      "word : recevoir\n",
      "[Synset('beget.v.01'), Synset('suffer.v.02'), Synset('grow.v.08'), Synset('receive.v.08'), Synset('get.v.03'), Synset('receive.v.02'), Synset('catch.v.18'), Synset('receive.v.13'), Synset('get.v.20'), Synset('receive.v.06'), Synset('entertain.v.02'), Synset('welcome.v.02'), Synset('get.v.14'), Synset('receive.v.12'), Synset('get.v.19'), Synset('bring.v.04'), Synset('receive.v.05'), Synset('catch.v.07'), Synset('draw.v.15'), Synset('catch.v.24'), Synset('pick_up.v.09'), Synset('get.v.25'), Synset('catch.v.22'), Synset('catch.v.21'), Synset('get.v.22'), Synset('receive.v.01'), Synset('accept.v.09'), Synset('accept.v.02'), Synset('accept.v.05'), Synset('bear.v.06'), Synset('get.v.21'), Synset('receive.v.10'), Synset('meet.v.11')]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Comments: \\n    - Improvement from the previous implementations. \\n    - tags can be easily adjusted if one wishes to include them in the list comprehension. \\n    - NOTE:  '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  improved spacy + nltk ## \n",
    "\n",
    "print(\"***improved spacy+nltk***\\n\")\n",
    "\n",
    "# create a filtered lemmas to exclude determiners (DET), adpositions(aka prepositions) (ADP), \n",
    "# punctuation (PUNCT), conjuctions (CONJ,CCONJ), numerals (NUM), symbols (SYM), spaces (NUM), \n",
    "# and non-alpha tokens. \n",
    "# Full list can be found at https://spacy.io/api/annotation\n",
    "\n",
    "tags = [\"DET\",\"ADP\",\"PUNCT\",\"CONJ\",\"CCONJ\",\"NUM\",\"SYM\",\"SPACE\"]\n",
    "flt_doc_lemmas = [(token.text, token.lemma_) for token in doc if token.pos_ not in tags and token.text.isalpha()]\n",
    "\n",
    "print(\"**filtered doc lemmas**\\n\")\n",
    "print(flt_doc_lemmas)\n",
    "\n",
    "# Now we will generate the synsets using these filtered lemmaS\n",
    "print(\"\\n**synsets**\\n\")\n",
    "\n",
    "# list comprehension of lemmatized words\n",
    "flt_synsets_fr = {tup[1]: wn.synsets(tup[1], lang='fra') for tup in flt_doc_lemmas}\n",
    "\n",
    "print_synsets(flt_synsets_fr)\n",
    "\n",
    "\"\"\"Comments: \n",
    "    - Improvement from the previous implementations. \n",
    "    - tags can be easily adjusted if one wishes to include them in the list comprehension. \n",
    "    - NOTE:  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Entity:OTTAWA |] [start:1] [end:9] [Label:MISC]\n",
      "[Entity:ministre canadienne des Affaires étrangères] [start:13] [end:56] [Label:ORG]\n",
      "[Entity:Chrystia Freeland] [start:58] [end:75] [Label:PER]\n",
      "[Entity:Amérique du Nord] [start:262] [end:278] [Label:LOC]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\"> \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    OTTAWA |\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " La \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    ministre canadienne des Affaires étrangères\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Chrystia Freeland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", qui a reçu une délégation du gouvernement mexicain, a estimé mardi que les droits de douane américains sur l'aluminium et l'acier devaient être «abolis» pour «un vrai libre-échange» en \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Amérique du Nord\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# spaCy NER & visualization ### \n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(\"[Entity:{}] [start:{}] [end:{}] [Label:{}]\".format(ent.text, ent.start_char, ent.end_char, ent.label_))\n",
    "    \n",
    "displacy.render(doc, style=\"ent\",jupyter=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Entity:Suchiate] [start:90] [end:98] [Label:MISC]\n",
      "[Entity:Guatemala du Mexique] [start:114] [end:134] [Label:LOC]\n",
      "[Entity:Institut national mexicain des migrations] [start:214] [end:255] [Label:ORG]\n",
      "[Entity:INM] [start:257] [end:260] [Label:MISC]\n",
      "[Entity:Centraméricains] [start:376] [end:391] [Label:LOC]\n",
      "[Entity:Tapachula] [start:520] [end:529] [Label:LOC]\n",
      "[Entity:Guatemala] [start:568] [end:577] [Label:LOC]\n",
      "[Entity:Etats-Unis] [start:671] [end:681] [Label:LOC]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">Chaque jour, les sans-papiers franchissent par centaines, parfois par milliers, le fleuve \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Suchiate\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       ", qui sépare le \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Guatemala du Mexique\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". Leur nombre est évalué à plus de 300 000 lors du premier trimestre 2019 par l’\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Institut national mexicain des migrations\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    INM\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       "), soit trois à quatre fois plus que les années précédentes. Du jamais-vu lié au nouveau phénomène des caravanes de \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Centraméricains\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", fuyant ensemble la misère et la violence de leurs pays d’origine. Ce tsunami migratoire provoque des goulots d’étranglement. A \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Tapachula\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", principale ville frontalière avec le \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Guatemala\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", les clandestins attendent en masse des permis de transit pour continuer leur route vers les \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Etats-Unis\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Another example taken from https://www.lemonde.fr/international/article/2019/05/11/au-mexique-la-double-crise-migratoire-tourne-au-casse-tete-pour-amlo_5460889_3210.html\n",
    "text = \"\"\"Chaque jour, les sans-papiers franchissent par centaines, parfois par milliers, le fleuve Suchiate, qui sépare le Guatemala du Mexique. Leur nombre est évalué à plus de 300 000 lors du premier trimestre 2019 par l’Institut national mexicain des migrations (INM), soit trois à quatre fois plus que les années précédentes. Du jamais-vu lié au nouveau phénomène des caravanes de Centraméricains, fuyant ensemble la misère et la violence de leurs pays d’origine. Ce tsunami migratoire provoque des goulots d’étranglement. A Tapachula, principale ville frontalière avec le Guatemala, les clandestins attendent en masse des permis de transit pour continuer leur route vers les Etats-Unis.\"\"\" \n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(\"[Entity:{}] [start:{}] [end:{}] [Label:{}]\".format(ent.text, ent.start_char, ent.end_char, ent.label_))\n",
    "    \n",
    "displacy.render(doc, style=\"ent\",jupyter=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

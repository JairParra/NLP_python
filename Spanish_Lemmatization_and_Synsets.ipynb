{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### *** French lemmatization and synsets with spacy and nltk *** ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ¿Un soborno de 100 millones de dólares? Los mexicanos se muestran indiferentes.\n",
      "        CIUDAD DE MÉXICO — La acusación de un testigo cayó como una bomba en Estados Unidos: uno de los capos de la droga más poderosos del mundo le había pagado un soborno de 100 millones de dólares a Enrique Peña Nieto, el expresidente de México.\n",
      "\n",
      "        Sin embargo, en México la revelación —de boca de un exaliado del narcotraficante Joaquín “el Chapo” Guzmán, en un tribunal de Nueva York— fue recibida con indiferencia.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "### Lemmatization ### \n",
    "\n",
    "# Note the wordnet included in the nltk corpus already includes Spanish\n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import wordnet as wn \n",
    "\n",
    "# Example political text taken from \n",
    "# https://www.nytimes.com/es/2019/01/16/pena-nieto-soborno-chapo/?rref=collection%2Fsectioncollection%2Fnyt-es&action=click&contentCollection=corrupcion-en-mexico&region=stream&module=stream_unit&version=latest&contentPlacement=4&pgtype=collection\n",
    "\n",
    "text = \"\"\" ¿Un soborno de 100 millones de dólares? Los mexicanos se muestran indiferentes.\n",
    "        CIUDAD DE MÉXICO — La acusación de un testigo cayó como una bomba en Estados Unidos: uno de los capos de la droga más poderosos del mundo le había pagado un soborno de 100 millones de dólares a Enrique Peña Nieto, el expresidente de México.\n",
    "\n",
    "        Sin embargo, en México la revelación —de boca de un exaliado del narcotraficante Joaquín “el Chapo” Guzmán, en un tribunal de Nueva York— fue recibida con indiferencia.\n",
    "        \"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***nltk tokenization*** \n",
      "\n",
      "['¿Un', 'soborno', 'de', '100', 'millones', 'de', 'dólares', '?', 'Los', 'mexicanos', 'se', 'muestran', 'indiferentes', '.', 'CIUDAD', 'DE', 'MÉXICO', '—', 'La', 'acusación', 'de', 'un', 'testigo', 'cayó', 'como', 'una', 'bomba', 'en', 'Estados', 'Unidos', ':', 'uno', 'de', 'los', 'capos', 'de', 'la', 'droga', 'más', 'poderosos', 'del', 'mundo', 'le', 'había', 'pagado', 'un', 'soborno', 'de', '100', 'millones', 'de', 'dólares', 'a', 'Enrique', 'Peña', 'Nieto', ',', 'el', 'expresidente', 'de', 'México', '.', 'Sin', 'embargo', ',', 'en', 'México', 'la', 'revelación', '—de', 'boca', 'de', 'un', 'exaliado', 'del', 'narcotraficante', 'Joaquín', '“', 'el', 'Chapo', '”', 'Guzmán', ',', 'en', 'un', 'tribunal', 'de', 'Nueva', 'York—', 'fue', 'recibida', 'con', 'indiferencia', '.'] \n",
      "\n",
      "[' ¿Un soborno de 100 millones de dólares?', 'Los mexicanos se muestran indiferentes.', 'CIUDAD DE MÉXICO — La acusación de un testigo cayó como una bomba en Estados Unidos: uno de los capos de la droga más poderosos del mundo le había pagado un soborno de 100 millones de dólares a Enrique Peña Nieto, el expresidente de México.', 'Sin embargo, en México la revelación —de boca de un exaliado del narcotraficante Joaquín “el Chapo” Guzmán, en un tribunal de Nueva York— fue recibida con indiferencia.'] \n",
      "\n",
      "***spacy tokenization*** \n",
      "\n",
      "['Un', 'soborno', 'de', 'millones', 'de', 'dólares', 'Los', 'mexicanos', 'se', 'muestran', 'indiferentes', 'CIUDAD', 'DE', 'MÉXICO', 'La', 'acusación', 'de', 'un', 'testigo', 'cayó', 'como', 'una', 'bomba', 'en', 'Estados', 'Unidos', 'uno', 'de', 'los', 'capos', 'de', 'la', 'droga', 'más', 'poderosos', 'del', 'mundo', 'le', 'había', 'pagado', 'un', 'soborno', 'de', 'millones', 'de', 'dólares', 'a', 'Enrique', 'Peña', 'Nieto', 'el', 'expresidente', 'de', 'México', 'Sin', 'embargo', 'en', 'México', 'la', 'revelación', 'boca', 'de', 'un', 'exaliado', 'del', 'narcotraficante', 'Joaquín', 'el', 'Chapo', 'Guzmán', 'en', 'un', 'tribunal', 'de', 'Nueva', 'fue', 'recibida', 'con', 'indiferencia'] \n",
      "\n",
      "[ ¿Un soborno de 100 millones de dólares?, Los mexicanos se muestran indiferentes.\n",
      "        , CIUDAD DE MÉXICO — La acusación de un testigo cayó como una bomba en Estados Unidos: uno de los capos de la droga más poderosos del mundo le había pagado un soborno de 100 millones de dólares a Enrique Peña Nieto, el expresidente de México.\n",
      "\n",
      "        , Sin embargo, en México la revelación —de boca de un exaliado del narcotraficante Joaquín “el Chapo” Guzmán, en un tribunal de Nueva York— fue recibida con indiferencia.\n",
      "        ] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Comments: \\n    spacy also does the job '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Tokenization ###\n",
    "\n",
    "## nltk ## \n",
    "print(\"***nltk tokenization*** \\n\")\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "word_tokens = [token for token in word_tokenize(text, language='spanish')] # tokenize by words\n",
    "sent_tokens = [sent for sent in sent_tokenize(text, language='spanish')] # tokenize by sentence\n",
    "print(word_tokens, \"\\n\") \n",
    "print(sent_tokens, \"\\n\")\n",
    "\n",
    "\"\"\"Comments: \n",
    "    nltk seems to do the job just right.\"\"\"\n",
    "\n",
    "## spacy ## \n",
    "\n",
    "print(\"***spacy tokenization*** \\n\")\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "# NOTE: The md model is more comprehensive but takes a bit more to load\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "sp_word_tokens = [token.text for token in doc if token.text.isalpha()]\n",
    "sp_sent_tokens = [sent for sent in doc.sents]\n",
    "print(sp_word_tokens, \"\\n\")\n",
    "print(sp_sent_tokens, \"\\n\")\n",
    "\n",
    "\"\"\" Comments: \n",
    "    spacy also does the job \"\"\"\n",
    "\n",
    "## polyglot ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**nltk lemmatization***\n",
      "\n",
      "[('soborno', 'soborn'), ('de', 'de'), ('millones', 'millon'), ('de', 'de'), ('dólares', 'dolar'), ('Los', 'los'), ('mexicanos', 'mexican'), ('se', 'se'), ('muestran', 'muestr'), ('indiferentes', 'indiferent'), ('CIUDAD', 'ciud'), ('DE', 'de'), ('MÉXICO', 'mexic'), ('La', 'la'), ('acusación', 'acus'), ('de', 'de'), ('un', 'un'), ('testigo', 'testig'), ('cayó', 'cay'), ('como', 'com'), ('una', 'una'), ('bomba', 'bomb'), ('en', 'en'), ('Estados', 'estad'), ('Unidos', 'unid'), ('uno', 'uno'), ('de', 'de'), ('los', 'los'), ('capos', 'cap'), ('de', 'de'), ('la', 'la'), ('droga', 'drog'), ('más', 'mas'), ('poderosos', 'poder'), ('del', 'del'), ('mundo', 'mund'), ('le', 'le'), ('había', 'hab'), ('pagado', 'pag'), ('un', 'un'), ('soborno', 'soborn'), ('de', 'de'), ('millones', 'millon'), ('de', 'de'), ('dólares', 'dolar'), ('a', 'a'), ('Enrique', 'enriqu'), ('Peña', 'peñ'), ('Nieto', 'niet'), ('el', 'el'), ('expresidente', 'expresident'), ('de', 'de'), ('México', 'mexic'), ('Sin', 'sin'), ('embargo', 'embarg'), ('en', 'en'), ('México', 'mexic'), ('la', 'la'), ('revelación', 'revel'), ('boca', 'boc'), ('de', 'de'), ('un', 'un'), ('exaliado', 'exali'), ('del', 'del'), ('narcotraficante', 'narcotraf'), ('Joaquín', 'joaquin'), ('el', 'el'), ('Chapo', 'chap'), ('Guzmán', 'guzman'), ('en', 'en'), ('un', 'un'), ('tribunal', 'tribunal'), ('de', 'de'), ('Nueva', 'nuev'), ('fue', 'fue'), ('recibida', 'recib'), ('con', 'con'), ('indiferencia', 'indiferent')] \n",
      "\n",
      "***spacy lemmatization***\n",
      "\n",
      "[('Un', 'Un'), ('soborno', 'sobornar'), ('de', 'de'), ('millones', 'millón'), ('de', 'de'), ('dólares', 'dólar'), ('Los', 'Los'), ('mexicanos', 'mexicano'), ('se', 'se'), ('muestran', 'mostrar'), ('indiferentes', 'indiferente'), ('CIUDAD', 'CIUDAD'), ('DE', 'DE'), ('MÉXICO', 'MÉXICO'), ('La', 'La'), ('acusación', 'acusación'), ('de', 'de'), ('un', 'uno'), ('testigo', 'testigo'), ('cayó', 'caer'), ('como', 'comer'), ('una', 'uno'), ('bomba', 'bombo'), ('en', 'en'), ('Estados', 'Estados'), ('Unidos', 'Unidos'), ('uno', 'unir'), ('de', 'de'), ('los', 'lo'), ('capos', 'capos'), ('de', 'de'), ('la', 'lo'), ('droga', 'drogar'), ('más', 'más'), ('poderosos', 'poderoso'), ('del', 'del'), ('mundo', 'mundo'), ('le', 'le'), ('había', 'haber'), ('pagado', 'pagar'), ('un', 'uno'), ('soborno', 'sobornar'), ('de', 'de'), ('millones', 'millón'), ('de', 'de'), ('dólares', 'dólar'), ('a', 'a'), ('Enrique', 'Enrique'), ('Peña', 'Peña'), ('Nieto', 'Nieto'), ('el', 'el'), ('expresidente', 'expresidente'), ('de', 'de'), ('México', 'México'), ('Sin', 'Sin'), ('embargo', 'embargar'), ('en', 'en'), ('México', 'México'), ('la', 'lo'), ('revelación', 'revelación'), ('boca', 'boca'), ('de', 'de'), ('un', 'uno'), ('exaliado', 'exaliado'), ('del', 'del'), ('narcotraficante', 'narcotraficante'), ('Joaquín', 'Joaquín'), ('el', 'el'), ('Chapo', 'Chapo'), ('Guzmán', 'Guzmán'), ('en', 'en'), ('un', 'uno'), ('tribunal', 'tribunal'), ('de', 'de'), ('Nueva', 'Nueva'), ('fue', 'ser'), ('recibida', 'recibir'), ('con', 'con'), ('indiferencia', 'indiferencia')]\n",
      "Lemma:  Un\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Comments: \\n    - Compared to nltk, spacy does an amazing job in lemmatizing French. '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Lemmatization ### \n",
    "\n",
    "## nltk ##\n",
    "print(\"**nltk lemmatization***\\n\")\n",
    "\n",
    "from nltk.stem.snowball import SpanishStemmer # from SnowballStemmer\n",
    "\n",
    "stemmer = SpanishStemmer() # instantiate the stemmer \n",
    "\n",
    "alpha_words = [w for w in word_tokens if w.isalpha()] # remove punctuation\n",
    "nltk_sp_stems = [(word, stemmer.stem(word)) for word in alpha_words]\n",
    "\n",
    "print(nltk_sp_stems, \"\\n\") \n",
    "\n",
    "\"\"\" Comments: \n",
    "    - As it can be seen, nltk does a very poor job in lemmatizing Spanish.\n",
    "    - An alternative could be to implement our own stemmer with the \n",
    "        stem.Regexp() function, but it looks quite time consuming, \n",
    "        given all the irregularities of the language. In fact, implementing \n",
    "        a new module would be a better idea.\"\"\"\n",
    "\n",
    "## spacy lemmatization: ##\n",
    "print(\"***spacy lemmatization***\\n\")\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_md\") # I used the medium model for better accuracy\n",
    "\n",
    "doc = nlp(text)\n",
    "doc_lemmas = [(token.text, token.lemma_) for token in doc if token.text.isalpha()]\n",
    "print(doc_lemmas)\n",
    "\n",
    "print(\"Lemma: \", doc_lemmas[0][1])\n",
    "\"\"\" Comments: \n",
    "    - Compared to nltk, spacy does an amazing job in lemmatizing French. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***nltk synsets***\n",
      "\n",
      "word : soborno\n",
      "[Synset('price.n.06')]\n",
      "\n",
      "word : de\n",
      "[Synset('delaware.n.04')]\n",
      "\n",
      "word : millones\n",
      "[]\n",
      "\n",
      "word : dólares\n",
      "[]\n",
      "\n",
      "word : Los\n",
      "[]\n",
      "\n",
      "word : mexicanos\n",
      "[]\n",
      "\n",
      "word : se\n",
      "[]\n",
      "\n",
      "word : muestran\n",
      "[]\n",
      "\n",
      "word : indiferentes\n",
      "[]\n",
      "\n",
      "word : CIUDAD\n",
      "[Synset('city.n.01'), Synset('township.n.01')]\n",
      "\n",
      "\n",
      "***spacy + nltk synsets***\n",
      "\n",
      "word : Un\n",
      "[]\n",
      "\n",
      "word : soborno\n",
      "[Synset('suborn.v.03'), Synset('sop.v.01')]\n",
      "\n",
      "word : de\n",
      "[Synset('delaware.n.04')]\n",
      "\n",
      "word : millones\n",
      "[Synset('million.n.01')]\n",
      "\n",
      "word : dólares\n",
      "[Synset('dollar.n.04'), Synset('dollar.n.03'), Synset('dollar.n.02'), Synset('dollar.n.01')]\n",
      "\n",
      "word : Los\n",
      "[]\n",
      "\n",
      "word : mexicanos\n",
      "[Synset('mexican.a.01')]\n",
      "\n",
      "word : se\n",
      "[]\n",
      "\n",
      "word : muestran\n",
      "[Synset('show.v.10'), Synset('indicate.v.02'), Synset('express.v.01'), Synset('testify.v.02'), Synset('picture.v.02'), Synset('show.v.04'), Synset('disclose.v.02'), Synset('register.v.07')]\n",
      "\n",
      "word : indiferentes\n",
      "[Synset('unconcerned.a.01'), Synset('blase.s.03'), Synset('indifferent.s.02'), Synset('uninterested.s.02'), Synset('inattentive.s.02'), Synset('listless.s.01'), Synset('halfhearted.s.01'), Synset('hostile.s.04'), Synset('apathetic.s.02'), Synset('unkindly.s.01'), Synset('unmoved.a.01'), Synset('indifferent.s.09'), Synset('indifferent.s.08'), Synset('inert.s.02'), Synset('unconcerned.s.02')]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Comments: \\n    - Better results but several entries are obviously wrong. \\n    - We could filter things like articles and propositions since finding synsets for these \\n        might not be very useful. '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Synsets ### \n",
    "\n",
    "## nltk ##\n",
    "\n",
    "print(\"***nltk synsets***\\n\")\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Note I decided to use alpha words and not stemmed given that the nltk stemmed words for \n",
    "# spa are so imprecise. The result would be a bunch of empty synsets. \n",
    "\n",
    "# create a dictionary of synsets for each word\n",
    "nltk_synsets_sp = {word: wn.synsets(word, lang='spa') for word in alpha_words}\n",
    "\n",
    "def print_synsets(synset, num_synsets=10):\n",
    "    \"\"\" expects a dictionary with synsets. \n",
    "        prints num_synsets number of synsets in the dictionary\"\"\"\n",
    "    i = 0\n",
    "    for key, val in synset.items():\n",
    "        if i < num_synsets: \n",
    "            print(\"word : {}\".format(key))\n",
    "            print(val)\n",
    "            i += 1\n",
    "            print()\n",
    "    \n",
    "print_synsets(nltk_synsets_sp)\n",
    "\n",
    "\"\"\" Comments: \n",
    "    Many words are missing synsets. \"\"\"\n",
    "\n",
    "## spacy + nltk ##\n",
    "\n",
    "print(\"\\n***spacy + nltk synsets***\\n\")\n",
    "\n",
    "spnlkt_synsest_sp = {tup[0]: wn.synsets(tup[1], lang='spa') for tup in doc_lemmas}\n",
    "\n",
    "print_synsets(spnlkt_synsest_sp) \n",
    "\n",
    "\"\"\" Comments: \n",
    "    - Better results but several entries are obviously wrong. \n",
    "    - We could filter things like articles and propositions since finding synsets for these \n",
    "        might not be very useful. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***improved spacy+nltk***\n",
      "\n",
      "**filtered doc lemmas**\n",
      "\n",
      "[('soborno', 'sobornar'), ('millones', 'millón'), ('dólares', 'dólar'), ('mexicanos', 'mexicano'), ('se', 'se'), ('muestran', 'mostrar'), ('indiferentes', 'indiferente'), ('CIUDAD', 'CIUDAD'), ('MÉXICO', 'MÉXICO'), ('acusación', 'acusación'), ('testigo', 'testigo'), ('cayó', 'caer'), ('como', 'comer'), ('bomba', 'bombo'), ('Estados', 'Estados'), ('Unidos', 'Unidos'), ('uno', 'unir'), ('capos', 'capos'), ('droga', 'drogar'), ('más', 'más'), ('poderosos', 'poderoso'), ('mundo', 'mundo'), ('le', 'le'), ('había', 'haber'), ('pagado', 'pagar'), ('soborno', 'sobornar'), ('millones', 'millón'), ('dólares', 'dólar'), ('Enrique', 'Enrique'), ('Peña', 'Peña'), ('Nieto', 'Nieto'), ('expresidente', 'expresidente'), ('México', 'México'), ('embargo', 'embargar'), ('México', 'México'), ('revelación', 'revelación'), ('boca', 'boca'), ('exaliado', 'exaliado'), ('narcotraficante', 'narcotraficante'), ('Joaquín', 'Joaquín'), ('Chapo', 'Chapo'), ('Guzmán', 'Guzmán'), ('tribunal', 'tribunal'), ('Nueva', 'Nueva'), ('fue', 'ser'), ('recibida', 'recibir'), ('indiferencia', 'indiferencia')]\n",
      "\n",
      "**synsets**\n",
      "\n",
      "word : sobornar\n",
      "[Synset('suborn.v.03'), Synset('sop.v.01')]\n",
      "\n",
      "word : millón\n",
      "[Synset('million.n.01')]\n",
      "\n",
      "word : dólar\n",
      "[Synset('dollar.n.04'), Synset('dollar.n.03'), Synset('dollar.n.02'), Synset('dollar.n.01')]\n",
      "\n",
      "word : mexicano\n",
      "[Synset('mexican.a.01')]\n",
      "\n",
      "word : se\n",
      "[]\n",
      "\n",
      "word : mostrar\n",
      "[Synset('show.v.10'), Synset('indicate.v.02'), Synset('express.v.01'), Synset('testify.v.02'), Synset('picture.v.02'), Synset('show.v.04'), Synset('disclose.v.02'), Synset('register.v.07')]\n",
      "\n",
      "word : indiferente\n",
      "[Synset('unconcerned.a.01'), Synset('blase.s.03'), Synset('indifferent.s.02'), Synset('uninterested.s.02'), Synset('inattentive.s.02'), Synset('listless.s.01'), Synset('halfhearted.s.01'), Synset('hostile.s.04'), Synset('apathetic.s.02'), Synset('unkindly.s.01'), Synset('unmoved.a.01'), Synset('indifferent.s.09'), Synset('indifferent.s.08'), Synset('inert.s.02'), Synset('unconcerned.s.02')]\n",
      "\n",
      "word : CIUDAD\n",
      "[Synset('city.n.01'), Synset('township.n.01')]\n",
      "\n",
      "word : MÉXICO\n",
      "[]\n",
      "\n",
      "word : acusación\n",
      "[Synset('blame.n.02'), Synset('accusation.n.01'), Synset('impeachment.n.01')]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Comments: \\n    - Improvement from the previous implementations. \\n    - tags can be easily adjusted if one wishes to include them in the list comprehension. \\n    - NOTE:  '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  improved spacy + nltk ## \n",
    "\n",
    "print(\"***improved spacy+nltk***\\n\")\n",
    "\n",
    "# create a filtered lemmas to exclude determiners (DET), adpositions(aka prepositions) (ADP), \n",
    "# punctuation (PUNCT), conjuctions (CONJ,CCONJ), numerals (NUM), symbols (SYM), spaces (NUM), \n",
    "# and non-alpha tokens. \n",
    "# Full list can be found at https://spacy.io/api/annotation\n",
    "\n",
    "tags = [\"DET\",\"ADP\",\"PUNCT\",\"CONJ\",\"CCONJ\",\"NUM\",\"SYM\",\"SPACE\"]\n",
    "flt_doc_lemmas = [(token.text, token.lemma_) for token in doc if token.pos_ not in tags and token.text.isalpha()]\n",
    "\n",
    "print(\"**filtered doc lemmas**\\n\")\n",
    "print(flt_doc_lemmas)\n",
    "\n",
    "# Now we will generate the synsets using these filtered lemmaS\n",
    "print(\"\\n**synsets**\\n\")\n",
    "\n",
    "# list comprehension of lemmatized words\n",
    "flt_synsets_sp = {tup[1]: wn.synsets(tup[1], lang='spa') for tup in flt_doc_lemmas}\n",
    "\n",
    "print_synsets(flt_synsets_sp)\n",
    "\n",
    "\"\"\"Comments: \n",
    "    - Improvement from the previous implementations. \n",
    "    - tags can be easily adjusted if one wishes to include them in the list comprehension. \n",
    "    - NOTE:  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Entity:MÉXICO] [start:99] [end:105] [Label:LOC]\n",
      "[Entity:en Estados Unidos] [start:155] [end:172] [Label:LOC]\n",
      "[Entity:Enrique Peña Nieto] [start:283] [end:301] [Label:PER]\n",
      "[Entity:México] [start:322] [end:328] [Label:LOC]\n",
      "[Entity:México] [start:355] [end:361] [Label:LOC]\n",
      "[Entity:—de] [start:376] [end:379] [Label:PER]\n",
      "[Entity:Joaquín] [start:420] [end:427] [Label:PER]\n",
      "[Entity:Chapo” Guzmán] [start:432] [end:445] [Label:PER]\n",
      "[Entity:Nueva York—] [start:465] [end:476] [Label:LOC]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> ¿Un soborno de 100 millones de dólares? Los mexicanos se muestran indiferentes.</br>        CIUDAD DE \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    MÉXICO\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " — La acusación de un testigo cayó como una bomba \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    en Estados Unidos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ": uno de los capos de la droga más poderosos del mundo le había pagado un soborno de 100 millones de dólares a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Enrique Peña Nieto\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", el expresidente de \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    México\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</br></br>        Sin embargo, en \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    México\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " la revelación \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    —de\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " boca de un exaliado del narcotraficante \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Joaquín\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " “el \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Chapo” Guzmán\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", en un tribunal de \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Nueva York—\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " fue recibida con indiferencia.\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### spaCy NER & visualization ### \n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(\"[Entity:{}] [start:{}] [end:{}] [Label:{}]\".format(ent.text, ent.start_char, ent.end_char, ent.label_))\n",
    "    \n",
    "displacy.render(doc, style=\"ent\",jupyter=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tildes & acentos in Spanish and Spellcheck Testing\n",
    "\n",
    "The following is a brief summary of important accents in Spanish, adapted mainly from *La Real Academia de la Lengua Española*\n",
    "\n",
    "ref: http://lema.rae.es/dpd/srv/search?id=Adwesaq4ND64VT09xQ\n",
    "\n",
    "**Definition**: An ortographic sign that is written to mark word stress according to a set of rules or to distinguish **homonymns** (words with same spelling but different meaning), in which case are called **tilde diacrítica**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word categorization according to number of syllables \n",
    "\n",
    "One syllable: **monosílabo** \n",
    "Two syllables: **bisílabo**\n",
    "Three syllables: **trisílabo** \n",
    "Four or more: **polisílabo**\n",
    "\n",
    "## Word categorization according to stress \n",
    "\n",
    "Divide the word by syllables, and then categorize according to where the stress falls. We count from right to left, thus the last syllable is called **última**, the one before is **penúltima** , the third from the right is **antepenúltima** , and the rest is **anteantepenúltima**, **anteanteantepenúltima** etc. \n",
    "\n",
    "Ex. the word *estratificación* \n",
    "\n",
    "etc. 'ti' -> `anteantepenúltima` 'fi' -> `antepenúltima` 'ca' -> `penúltima` 'ción' -> `ultima`  \n",
    "\n",
    "### Categorization \n",
    "\n",
    "- A word is called **aguda** if it has the stress on the *última sílaba* \n",
    "- A word is called **grave** if it has the stress on the *penúltima sílaba* \n",
    "- A word is called **esdrújula** if it has the stress on the *antepenúltima sílaba* \n",
    "- A word is called **sobreesdrújula** if it has the stress on the *anteantepenúltima sílaba.* \n",
    "\n",
    "## Distribution according to number of syllables \n",
    "\n",
    "### Polisílabos (2+ syllables)\n",
    "\n",
    "- **Palabras agudas**: Mark the stress to words that end in **-n, -s, or a vowel**, unless it has an extra consonant before.\n",
    "- **Palabras graves**: Mark the stress if the word **does not end in -n, -s, or vowel**, and also when it has an extra consonant before. \n",
    "- **Palabras esdrújulas and sobreesdrújulas**: Always mark the stress.  \n",
    "\n",
    "### Monosílabos (1 syllable) \n",
    "- Don't take an accent unless is a **tilde diacrítica**\n",
    "\n",
    "\n",
    "## Tilde diacrítica \n",
    "\n",
    "**Definition**: We call a **tilde diacrítica** the tilde we write to ditinguish homonyms in written text. These happen frequently on monosílabos. \n",
    "\n",
    "The following is a dictionary of some of these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "\n",
    "import re\n",
    "import spacy \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import trange\n",
    "from spellchecker import SpellChecker \n",
    "\n",
    "spell = SpellChecker(language='es') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the language model \n",
    "nlp = spacy.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the following three objects: \n",
    "- a dictionary whose keys are the words with tile diacrítica, mapping to a list of POS tags \n",
    "- a full-list of all tile diacrítica words\n",
    "- a list of tuples of the tilde diacrítica words (with/without) \n",
    "\n",
    "Side note: spaCy POS accuracy for Spanish is about **96.9%**. \n",
    "See https://spacy.io/usage/facts-figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'dé', 'el', 'él', 'mas', 'más', 'mi', 'mí', 'se', 'sé', 'si', 'sí', 'te', 'té', 'tu', 'como', 'cómo', 'cuando', 'cuándo', 'cúal', 'cual', 'cuanto', 'cuánto', 'dónde', 'donde', 'qué', 'que', 'quién', 'quien', 'solo', 'sólo']\n",
      "[('de', 'dé'), ('el', 'él'), ('mas', 'más'), ('mi', 'mí'), ('se', 'sé'), ('si', 'sí'), ('te', 'té'), ('tu', 'como'), ('cómo', 'cuando'), ('cuándo', 'cúal'), ('cual', 'cuanto'), ('cuánto', 'dónde'), ('donde', 'qué'), ('que', 'quién'), ('quien', 'solo')]\n"
     ]
    }
   ],
   "source": [
    "# The TAGS assigned are spaCy annotation tags: \n",
    "# https://spacy.io/api/annotation\n",
    "\n",
    "categ_dict ={\n",
    "    'de':['PREP'], \n",
    "    'dé':['VERB'], \n",
    "    'el':['DET'],  \n",
    "    'él':['PRON'], \n",
    "    'mas':['CONJ','CCONJ'], \n",
    "    'más':['ADV','ADJ','PRN'], \n",
    "    'mi':['ADJ','DET'], \n",
    "    'mí':['PRON'], \n",
    "    'se':['PRON'], \n",
    "    'sé':['VERB'], \n",
    "    'si':['CONJ','CCONJ'], \n",
    "    'sí':['ADV'], \n",
    "    'te':['PRON'], \n",
    "    'té':['NOUN'], \n",
    "    'tu':['DET'], \n",
    "    'como':['CONJ','SCONJ'], \n",
    "    'cómo':['PRON'], \n",
    "    'cuando':['CONJ','SCONJ'], \n",
    "    'cuándo':['PRON'],\n",
    "    'cúal':['ADJ'],\n",
    "    'cual':['PRON'], \n",
    "    'cuanto':['CONJ','SCONJ'], \n",
    "    'cuánto':['DET'], \n",
    "    'dónde':['PRON'], # question \n",
    "    'donde':['PRON'], \n",
    "    'qué':['PRON'],  \n",
    "    'que':['SCONJ'], \n",
    "    'quién':['PROPN'], # proper noun \n",
    "    'quien':['PRON'], \n",
    "    'solo':['ADJ'], \n",
    "    'sólo':['ADJ','ADJ'],     \n",
    "}\n",
    "\n",
    "# Create two dictionaries with the whole list and correspondences \n",
    "full_list = list(categ_dict.keys())  # collection of tilde diacrítica words\n",
    "all_pairs = [(full_list[i], full_list[i+1]) for i in range(0,len(full_list)-1,2)]\n",
    "\n",
    "\n",
    "print(full_list) #  \n",
    "print(all_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 0:\n",
      "POS tags: \n",
      " [[('De', 'ADP'), ('qué', 'DET'), ('quieres', 'AUX'), ('hablar', 'VERB'), ('hoy', 'ADV'), ('?', 'PUNCT')]]\n",
      "Tilde diacritica tokens for doc + dict POS 0 : \n",
      "[('qué', ['PRON'])]\n",
      "Tilde diacritica lemmas for doc + dict POS 0 : \n",
      "[('qué', ['PRON'])]\n",
      "\n",
      "Text 1:\n",
      "POS tags: \n",
      " [[('Quiero', 'VERB'), ('que', 'SCONJ'), ('me', 'PRON'), ('dé', 'VERB'), ('un', 'DET'), ('poco', 'PRON'), ('de', 'ADP'), ('tiempo', 'NOUN')]]\n",
      "Tilde diacritica tokens for doc + dict POS 1 : \n",
      "[('que', ['SCONJ']), ('dé', ['VERB']), ('de', ['PREP'])]\n",
      "Tilde diacritica lemmas for doc + dict POS 1 : \n",
      "[('que', ['SCONJ']), ('de', ['PREP'])]\n",
      "\n",
      "Text 2:\n",
      "POS tags: \n",
      " [[('Ya', 'ADV'), ('no', 'ADV'), ('quiero', 'VERB'), ('comer', 'VERB'), ('más', 'ADV'), ('!', 'PUNCT')]]\n",
      "Tilde diacritica tokens for doc + dict POS 2 : \n",
      "[('más', ['ADV', 'ADJ', 'PRN'])]\n",
      "Tilde diacritica lemmas for doc + dict POS 2 : \n",
      "[('más', ['ADV', 'ADJ', 'PRN'])]\n",
      "\n",
      "Text 3:\n",
      "POS tags: \n",
      " [[('Yo', 'PRON'), ('sé', 'VERB'), (',', 'PUNCT'), ('tu', 'DET'), ('quieres', 'VERB'), ('que', 'SCONJ'), ('él', 'PRON'), ('se', 'PRON'), ('lave', 'VERB'), ('las', 'DET'), ('manos', 'NOUN')]]\n",
      "Tilde diacritica tokens for doc + dict POS 3 : \n",
      "[('sé', ['VERB']), ('tu', ['DET']), ('que', ['SCONJ']), ('él', ['PRON']), ('se', ['PRON'])]\n",
      "Tilde diacritica lemmas for doc + dict POS 3 : \n",
      "[('tu', ['DET']), ('que', ['SCONJ']), ('él', ['PRON']), ('se', ['PRON'])]\n",
      "\n",
      "Text 4:\n",
      "POS tags: \n",
      " [[('Sólo', 'ADV'), ('el', 'DET'), ('tiempo', 'NOUN'), ('decidirá', 'VERB'), ('qué', 'PRON'), ('se', 'PRON'), ('quiere', 'VERB'), ('hacer', 'VERB')]]\n",
      "Tilde diacritica tokens for doc + dict POS 4 : \n",
      "[('el', ['DET']), ('qué', ['PRON']), ('se', ['PRON'])]\n",
      "Tilde diacritica lemmas for doc + dict POS 4 : \n",
      "[('el', ['DET']), ('qué', ['PRON']), ('se', ['PRON'])]\n"
     ]
    }
   ],
   "source": [
    "# Notice that we can obtain the POS tags for all of these \n",
    "# Create some examples in which these words are employed\n",
    "texts= [\"De qué quieres hablar hoy? \", \n",
    "        \"Quiero que me dé un poco de tiempo\", \n",
    "       \"Ya no quiero comer más!\", \n",
    "       \"Yo sé, tu quieres que él se lave las manos\", \n",
    "       \"Sólo el tiempo decidirá qué se quiere hacer\"] \n",
    "\n",
    "docs = nlp.pipe(texts)\n",
    "\n",
    "for i,doc in enumerate(docs):\n",
    "    \n",
    "    tokens = [token.text for token in doc]  # obtain tokens\n",
    "    lemmas = [token.lemma_ for token in doc] # obtain lemmas \n",
    "    \n",
    "    print(\"\\nText {}:\".format(i))\n",
    "    print(\"POS tags: \\n\", [[(token.text, token.pos_) for token in doc]])\n",
    "    \n",
    "    # tilde diacrítica words (tdw) found among the tokens, \n",
    "    # along with their respective POS taggings. Note these are the ones we \n",
    "    # annotated manually. Compare these with spaCy's ones. \n",
    "    tdw_tokens = [(token.text, categ_dict[token.text]) for token in doc if token.text in full_list] \n",
    "    tdw_lemmas = [(token.lemma_, categ_dict[token.lemma_]) for token in doc if token.lemma_ in full_list] \n",
    "    \n",
    "    # display \n",
    "    print(\"Tilde diacritica tokens for doc + dict POS {} : \\n{}\".format(i, tdw_tokens))\n",
    "    print(\"Tilde diacritica lemmas for doc + dict POS {} : \\n{}\".format(i, tdw_lemmas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in the above that in some cases, the **tilde (stress mark) disappears when the sentence is lemmatized**. \n",
    "\n",
    "## Testing pyspellchecker \n",
    "\n",
    "In this part we will apply some basic tests to assess the performance of pyspellchecker on Spanish. From the documentation, \n",
    "\n",
    "\"*It uses a Levenshtein Distance algorithm to find permutations within an edit distance of 2 from the original word. It then compares all permutations (insertions, deletions, replacements, and transpositions) to known words in a word frequency list. Those words that are found more often in the frequency list are **more likely** the correct results.*\"\n",
    "\n",
    "It uses the following algorithm: \n",
    "\n",
    "![](../figs/Levenshtein_distance.jpg)\n",
    "\n",
    "The important thing to notice is that whenever we have long words, changing the `edit_distance` parameter to 1 works better, according to documentation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misspelled: \n",
      " {'aqquí'}\n",
      "in_frequency list: \n",
      " {'la', 'solicito', 'algo', 'que', 'mañana', '!', 'en', 'pase'}\n",
      "Input word: aqquí\n",
      "\n",
      "correction:  aquí\n",
      "candidates:  {'aquí'}\n",
      "probability of mispelled word:  0.0\n"
     ]
    }
   ],
   "source": [
    "### Basic Usage ### \n",
    "spell = SpellChecker(language='es') # Spanish dictionary  \n",
    "\n",
    "\n",
    "\n",
    "# from spaCY\n",
    "text0 = \"Solicito que algo pase aqquí mañana en la mañana !\" # note the word \"aqquí\" is misspelled \n",
    "doc = nlp(text0) \n",
    "tokens = [token.text for token in doc] \n",
    "lemma_tokens = [token.lemma_ for token in doc]\n",
    "\n",
    "\n",
    "\n",
    "# find those words that might be misspelled \n",
    "misspelled = spell.unknown(tokens)\n",
    "\n",
    "# words that are in the frequency list \n",
    "in_freq = spell.known(tokens) \n",
    "\n",
    "print(\"misspelled: \\n\", misspelled)\n",
    "print(\"in_frequency list: \\n\", in_freq)\n",
    "\n",
    "\n",
    "for word in misspelled: \n",
    "    \n",
    "    print(\"Input word: {}\\n\".format(word)) \n",
    "    \n",
    "    # Get the one 'most likely' answer  \n",
    "    print(\"correction: \", spell.correction(word))\n",
    "    \n",
    "    # Get a list of the 'likely' options  \n",
    "    print(\"candidates: \", spell.candidates(word))\n",
    "    \n",
    "    # Get probability of the input word occurring \n",
    "    print(\"probability of mispelled word: \", spell.word_probability(word))\n",
    "    \n",
    "del(misspelled) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the tilde diacrítica list to the dictionary  \n",
    "\n",
    "As a side note, notice that we can add the list above to the dictionary if necessary, as well as any other list of words (such as names) that we would like to have as correctly spelled. This can be done in the following fashion: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell2 = SpellChecker() # create a new spellcheck instance \n",
    "spell2.word_frequency.load_words(full_list) # load full list of tilde diac. words \n",
    "spell2.word_frequency.remove_words(full_list) # remove a list fo words from the spellchecker "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description: \n",
      " 1) Requiero que se entregue copia de la investigación de mercados realizado por COMESA EN LA CUAL SE DETERMINA CUALES SON LAS MEJORES CONDICIONES PARA EL ESTADO PARA LA ADJUCACION DIRECTA NO. SA-018TQA001-N231-2013.  2) REQUIERO QUE SE ENTREGUE COPIA DEL ACUERDO No 04/E25/2013   3) REQUIERO COPIA DE LA MINUTA DE  LA SESSION VIGESIMA QUINTA EXTRAORDINARIA DE FECHA DE 30 DICIEMBRE DE 2013  DEL CAAS EN COMESA   4) REQUIERO COPIA DEL ACTA  DE  LA SESION VIGESIMA QUINTA EXTRAORDINARIA DE FECHA DE 30 DICIEMBRE DE 2013  DEL CAAS EN COMESA   5) DE ACUERDO AL ART 41 FRACCION III DE LA LEY AASSP    III. Existan circunstancias que puedan provocar pérdidas o costos adicionales importantes   cuantificados y justificados;   Solicito a COMESA ME ENTREGUE UN DOCUMENTO O ACTA EN LA CUAL ME DIGAN CUALES  SON LOS SUPUESTOS QUE ELLOS INDICAN QUE PUEDEN PROVOCAR PERDIDAS O COSTOS ADICIONALES IMPORTANTES Y QUE ESTAN CUANTIFICADOS Y JUSTIFICADOS.  6)SOLICITO UN DOCUMENTO EN LA CUAL ME INDIQUEN CUALES FUERON LAS PERSONAS DE COMESA QUE AUTORIZARON LA REALIZACION DEL CONTRATO\n",
      "\n",
      "description: \n",
      " Favor de proporcionar toda la documentación relacionada con las acciones que fundamentan y dan aplicación del programa federal llamado CRUZADA NACIONAL CONTRA EL HAMBRE  así como los siguientes documentos: Presupuestos autorizados por la cámara de diputados en la sesión de diciembre de 2012 para cada una de las dependencias  organismos descentralizados y secretarias federales que participan en el mencionado programa y que van a ser aplicados en el ámbito federal para la nueva política social de este programa. Relación detallada de aplicaciones programadas de estos presupuestos por dependencias  organismos descentralizados y secretarias federales; para cada uno de los estados y de los 400 municipios del país seleccionados para su aplicación. Porcentaje e indice de pobreza y su relación con el contexto nacional  que tiene cada uno de estos estados y los 400 municipios donde vaya a aplicarse dicho programa. Detallar plan de acciones gubernamentales a ser aplicados por todas y cada una de las dependencias mencionadas involucradas y lograr tener  como se menciona en el programa  resultados a ser medidos y tangibles dentro del primer año de su aplicación. Agradezco su atención.    \n"
     ]
    }
   ],
   "source": [
    "# loading some of the request data \n",
    "data = pd.read_csv('../data_clean/request_texts.txt', sep='|')\n",
    "descriptions= data['DESCRIPCIONSOLICITUD'][0:11]\n",
    "print(\"description: \\n\", descriptions[0])\n",
    "print(\"\\ndescription: \\n\", descriptions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to obtain the mispelled words , the most likely words, the likely corrections and the probability of the wrong inputs occurring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make this into a function \n",
    "def spellcheck_test(texts, \n",
    "                    get_unknown=True, \n",
    "                    get_known=False, \n",
    "                    lowercase = False,\n",
    "                    verbose=True): \n",
    "    \n",
    "    # create an empty dataframe \n",
    "    df = pd.DataFrame(columns=['text','misspelled','correction','prob_wrong_input','num_tokens']) \n",
    "    \n",
    "    misspelled_lists = []\n",
    "    corrections_lists= [] \n",
    "    prob_wrong_input_lists = [] \n",
    "    num_tokens = []\n",
    "    num_misspelled = []\n",
    "    prop_misspelled = []\n",
    "    \n",
    "    # initialize a pipeline of fitted texts \n",
    "    docs = nlp.pipe(texts)\n",
    "    \n",
    "    for id, doc in tqdm_notebook(enumerate(docs), desc= 'processing text...'): \n",
    "        \n",
    "        print(\"******\\nText: {}\\n******\\n\".format(id))\n",
    "                \n",
    "        # obtain raw tokens lists \n",
    "        tokens = [token.text if lowercase else token.text.lower() for token in doc] \n",
    "                \n",
    "#         # obtain lemmas for all tokens \n",
    "#         lemmas = [token.lemma_ if lowercase else token.lemma_.lower() for token in doc]\n",
    "        \n",
    "        # find those words that might be misspelled \n",
    "        misspelled = [token for token in spell.unknown(tokens) if ' ' not in token]  \n",
    "        misspelled_lists += [misspelled] # add the list of misspelled words \n",
    "                \n",
    "        # obtain probability of mispelled words happening\n",
    "        probabilities = {word:spell.word_probability(word) for word in tqdm_notebook(misspelled, \n",
    "                                                                                        desc='finding misspelled words...')}  \n",
    "        prob_wrong_input_lists += [probabilities]\n",
    "        if verbose: \n",
    "            print(\"Misspelled words & probabilities: \\n\", probabilities)\n",
    "\n",
    "        # obtain corrections (NOTE: This part is VERY slow, am I doing something wrong?)\n",
    "        corrections = [spell.correction(word) for word in tqdm_notebook(misspelled, \"finding input correction...\")]\n",
    "        corrections_lists += [corrections]\n",
    "        if verbose: \n",
    "            print(\"Corrections: \\n\", corrections)\n",
    "            \n",
    "        # number of tokens per text \n",
    "        num_tokens += [len(tokens)]\n",
    "        \n",
    "        # number of misspelled tokens \n",
    "        num_misspelled += [len(misspelled)]\n",
    "        \n",
    "        # proportion of misspelled tokens \n",
    "        prop_misspelled += [len(misspelled)/len(tokens)]         \n",
    "        \n",
    "    # build the returning data frame \n",
    "    df['text'] = texts \n",
    "    df['misspelled'] = misspelled_lists    \n",
    "    df['correction'] = corrections_lists\n",
    "    df['prob_wrong_input'] = prob_wrong_input_lists\n",
    "    df['num_tokens'] = num_tokens\n",
    "    df['num_misspelled'] = num_misspelled\n",
    "    df['proportion_misspelled'] = prop_misspelled\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6ea02022b14cf78051379ee3821262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='processing text...', max=1, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "Text: 0\n",
      "******\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c764dbb52a004e0b8dcd1060ffdd6210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding misspelled words...', max=12, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misspelled words & probabilities: \n",
      " {'cuantificados': 0.0, 'sa-018tqa001-n231': 0.0, '6)solicito': 0.0, 'vigesima': 0.0, '04/e25/2013': 0.0, 'session': 0.0, 'caas': 0.0, 'aassp': 0.0, 'realizacion': 0.0, 'fraccion': 0.0, 'comesa': 0.0, 'adjucacion': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c0a15c46f34322b63788952a1445a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding input correction...', max=12, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrections: \n",
      " ['cualificados', 'sa-018tqa001-n231', 'solicito', 'vigésima', '04e252013', 'sesion', 'casa', 'cass', 'realización', 'fracción', 'comes', 'educacion']\n",
      "******\n",
      "Text: 1\n",
      "******\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d82da3f1fd4447fbaf90d3f3411a1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding misspelled words...', max=3, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misspelled words & probabilities: \n",
      " {'medidos': 0.0, 'descentralizados': 0.0, 'fundamentan': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4340f4abde48c3a32d0632fe84ea0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding input correction...', max=3, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrections: \n",
      " ['medios', 'descentralizados', 'fundamental']\n",
      "******\n",
      "Text: 2\n",
      "******\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b1b7fabc884c6a9117e9a2a9dc5217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding misspelled words...', max=15, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misspelled words & probabilities: \n",
      " {'no.': 0.0, '2300-a001': 0.0, '05/06/98': 0.0, 'ct011': 0.0, '20/06/2000': 0.0, '1.-': 0.0, 'institucionales': 0.0, 'normativos': 0.0, 'realizacion': 0.0, 'planeacion': 0.0, 'actualizacion': 0.0, 'sustantivas': 0.0, '2.-': 0.0, 'deroga': 0.0, 'emision': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31425173986457ab361eb73d12e1dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding input correction...', max=15, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrections: \n",
      " ['no', '2300001', '050698', '011', '20062000', '1.', 'instituciones', 'informativos', 'realización', 'planeación', 'actualización', 'sustancias', '2.', 'droga', 'emisión']\n",
      "******\n",
      "Text: 3\n",
      "******\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d1441fd2744ea5acc3b1727f0d8e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding misspelled words...', max=3, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misspelled words & probabilities: \n",
      " {'expide': 0.0, 'consumibles': 0.0, 'mensualizado': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd8110331ba44f5b2eed661c515fe24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding input correction...', max=3, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrections: \n",
      " ['expire', 'consumibles', 'mensualidad']\n",
      "******\n",
      "Text: 4\n",
      "******\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d071e9c12c4a6b80e27a8494a95672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding misspelled words...', max=4, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misspelled words & probabilities: \n",
      " {'tuxpan': 0.0, 'solicitadas': 0.0, 'solicitad': 0.0, '¿': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56f9d04d0844c1c99d8ea801e2eb5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding input correction...', max=4, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrections: \n",
      " ['culpan', 'solicitada', 'solicitud', 'a']\n",
      "******\n",
      "Text: 5\n",
      "******\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5b513459574ffc97fd7c34d51f7d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding misspelled words...', max=1, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misspelled words & probabilities: \n",
      " {'ifai': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2930b4eacc754f9cab4425fa1719c966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding input correction...', max=1, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrections: \n",
      " ['fai']\n",
      "******\n",
      "Text: 6\n",
      "******\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97453b4bf3041e2b10d8d505f6bb59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding misspelled words...', max=3, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misspelled words & probabilities: \n",
      " {'09dpr1936a': 0.0, 'cct': 0.0, 'escutia': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f4913a7e0f483092cde5a59ab95587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding input correction...', max=3, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrections: \n",
      " ['09dpr1936a', 'cat', 'escucha']\n",
      "******\n",
      "Text: 7\n",
      "******\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35023a6e91b048abac3645c80781f77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='finding misspelled words...', max=1, style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misspelled words & probabilities: \n",
      " {}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2d868a5caa434894ff6d71276eeacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='finding input correction...', max=1, style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrections: \n",
      " []\n",
      "******\n",
      "Text: 8\n",
      "******\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c774f6b5445472ea00f44b6e9e5e89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding misspelled words...', max=22, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misspelled words & probabilities: \n",
      " {'revocacion': 0.0, 'elaboracion': 0.0, 'inicadas': 0.0, 'imposicion': 0.0, 'promovio': 0.0, 'alude': 0.0, 'inciadas': 0.0, 'tubieron': 0.0, 'derivaron': 0.0, 'dictamenes': 0.0, 'decomisos': 0.0, 'originadas': 0.0, 'originados': 0.0, 'conseciones': 0.0, 'clausuras': 0.0, 'ascendio': 0.0, 'recaudados': 0.0, '¿': 0.0, 'contensioso': 0.0, 'peritajes': 0.0, 'sancion': 0.0, 'lgeepa': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770d139952494a909bb3d6204757334b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding input correction...', max=22, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrections: \n",
      " ['revocación', 'elaboración', 'indicadas', 'imposición', 'promovido', 'ayude', 'iniciadas', 'tuvieron', 'derribaron', 'dictamen', 'decomiso', 'originales', 'originado', 'condiciones', 'clausura', 'ascendido', 'recaudador', 'a', 'contensioso', 'peritaje', 'cancion', 'leela']\n",
      "******\n",
      "Text: 9\n",
      "******\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ffcf024f6e041f38e5c01ebf39b7f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding misspelled words...', max=2, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misspelled words & probabilities: \n",
      " {'dependendecnia': 0.0, 'apf': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92e99d6bc79421797d959d7224f7f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='finding input correction...', max=2, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrections: \n",
      " ['dependendecnia', 'alf']\n",
      "******\n",
      "Text: 10\n",
      "******\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1340304fb864a4d98a31e0fe2cc0a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='finding misspelled words...', max=1, style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misspelled words & probabilities: \n",
      " {}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f761103ee70540dfbbb23cf46d2c7f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='finding input correction...', max=1, style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrections: \n",
      " []\n"
     ]
    }
   ],
   "source": [
    "descriptions= data['DESCRIPCIONSOLICITUD'][0:11]\n",
    "df = spellcheck_test(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>misspelled</th>\n",
       "      <th>correction</th>\n",
       "      <th>prob_wrong_input</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>num_misspelled</th>\n",
       "      <th>proportion_misspelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1) Requiero que se entregue copia de la invest...</td>\n",
       "      <td>[cuantificados, sa-018tqa001-n231, 6)solicito,...</td>\n",
       "      <td>[cualificados, sa-018tqa001-n231, solicito, vi...</td>\n",
       "      <td>{'cuantificados': 0.0, 'sa-018tqa001-n231': 0....</td>\n",
       "      <td>195</td>\n",
       "      <td>12</td>\n",
       "      <td>0.061538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Favor de proporcionar toda la documentación re...</td>\n",
       "      <td>[medidos, descentralizados, fundamentan]</td>\n",
       "      <td>[medios, descentralizados, fundamental]</td>\n",
       "      <td>{'medidos': 0.0, 'descentralizados': 0.0, 'fun...</td>\n",
       "      <td>196</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En archivo electronico  favor de aportar compl...</td>\n",
       "      <td>[no., 2300-a001, 05/06/98, ct011, 20/06/2000, ...</td>\n",
       "      <td>[no, 2300001, 050698, 011, 20062000, 1., insti...</td>\n",
       "      <td>{'no.': 0.0, '2300-a001': 0.0, '05/06/98': 0.0...</td>\n",
       "      <td>165</td>\n",
       "      <td>15</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Con fundamento en lo previsto en los Artículos...</td>\n",
       "      <td>[expide, consumibles, mensualizado]</td>\n",
       "      <td>[expire, consumibles, mensualidad]</td>\n",
       "      <td>{'expide': 0.0, 'consumibles': 0.0, 'mensualiz...</td>\n",
       "      <td>263</td>\n",
       "      <td>3</td>\n",
       "      <td>0.011407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>¿De que manera la Secretaría de Marina da a co...</td>\n",
       "      <td>[tuxpan, solicitadas, solicitad, ¿]</td>\n",
       "      <td>[culpan, solicitada, solicitud, a]</td>\n",
       "      <td>{'tuxpan': 0.0, 'solicitadas': 0.0, 'solicitad...</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "      <td>0.028986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Se solicita información que detalle las resolu...</td>\n",
       "      <td>[ifai]</td>\n",
       "      <td>[fai]</td>\n",
       "      <td>{'ifai': 0.0}</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SOLICITO CONOCES LA APLICACION DE LOS BIENES C...</td>\n",
       "      <td>[09dpr1936a, cct, escutia]</td>\n",
       "      <td>[09dpr1936a, cat, escucha]</td>\n",
       "      <td>{'09dpr1936a': 0.0, 'cct': 0.0, 'escutia': 0.0}</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>0.051724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Deseo conocer el fundamento legal por el que e...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>¿numero de denuncias populares inciadas durant...</td>\n",
       "      <td>[revocacion, elaboracion, inicadas, imposicion...</td>\n",
       "      <td>[revocación, elaboración, indicadas, imposició...</td>\n",
       "      <td>{'revocacion': 0.0, 'elaboracion': 0.0, 'inica...</td>\n",
       "      <td>230</td>\n",
       "      <td>22</td>\n",
       "      <td>0.095652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RELACION CON TODOS LOS NOMBRES Y CARGOS (INCLU...</td>\n",
       "      <td>[dependendecnia, apf]</td>\n",
       "      <td>[dependendecnia, alf]</td>\n",
       "      <td>{'dependendecnia': 0.0, 'apf': 0.0}</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HORARIOS DE TRABAJO Y PRESTACIONES QUE PERCIBE...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   1) Requiero que se entregue copia de la invest...   \n",
       "1   Favor de proporcionar toda la documentación re...   \n",
       "2   En archivo electronico  favor de aportar compl...   \n",
       "3   Con fundamento en lo previsto en los Artículos...   \n",
       "4   ¿De que manera la Secretaría de Marina da a co...   \n",
       "5   Se solicita información que detalle las resolu...   \n",
       "6   SOLICITO CONOCES LA APLICACION DE LOS BIENES C...   \n",
       "7   Deseo conocer el fundamento legal por el que e...   \n",
       "8   ¿numero de denuncias populares inciadas durant...   \n",
       "9   RELACION CON TODOS LOS NOMBRES Y CARGOS (INCLU...   \n",
       "10  HORARIOS DE TRABAJO Y PRESTACIONES QUE PERCIBE...   \n",
       "\n",
       "                                           misspelled  \\\n",
       "0   [cuantificados, sa-018tqa001-n231, 6)solicito,...   \n",
       "1            [medidos, descentralizados, fundamentan]   \n",
       "2   [no., 2300-a001, 05/06/98, ct011, 20/06/2000, ...   \n",
       "3                 [expide, consumibles, mensualizado]   \n",
       "4                 [tuxpan, solicitadas, solicitad, ¿]   \n",
       "5                                              [ifai]   \n",
       "6                          [09dpr1936a, cct, escutia]   \n",
       "7                                                  []   \n",
       "8   [revocacion, elaboracion, inicadas, imposicion...   \n",
       "9                               [dependendecnia, apf]   \n",
       "10                                                 []   \n",
       "\n",
       "                                           correction  \\\n",
       "0   [cualificados, sa-018tqa001-n231, solicito, vi...   \n",
       "1             [medios, descentralizados, fundamental]   \n",
       "2   [no, 2300001, 050698, 011, 20062000, 1., insti...   \n",
       "3                  [expire, consumibles, mensualidad]   \n",
       "4                  [culpan, solicitada, solicitud, a]   \n",
       "5                                               [fai]   \n",
       "6                          [09dpr1936a, cat, escucha]   \n",
       "7                                                  []   \n",
       "8   [revocación, elaboración, indicadas, imposició...   \n",
       "9                               [dependendecnia, alf]   \n",
       "10                                                 []   \n",
       "\n",
       "                                     prob_wrong_input  num_tokens  \\\n",
       "0   {'cuantificados': 0.0, 'sa-018tqa001-n231': 0....         195   \n",
       "1   {'medidos': 0.0, 'descentralizados': 0.0, 'fun...         196   \n",
       "2   {'no.': 0.0, '2300-a001': 0.0, '05/06/98': 0.0...         165   \n",
       "3   {'expide': 0.0, 'consumibles': 0.0, 'mensualiz...         263   \n",
       "4   {'tuxpan': 0.0, 'solicitadas': 0.0, 'solicitad...         138   \n",
       "5                                       {'ifai': 0.0}          92   \n",
       "6     {'09dpr1936a': 0.0, 'cct': 0.0, 'escutia': 0.0}          58   \n",
       "7                                                  {}          43   \n",
       "8   {'revocacion': 0.0, 'elaboracion': 0.0, 'inica...         230   \n",
       "9                 {'dependendecnia': 0.0, 'apf': 0.0}          55   \n",
       "10                                                 {}          35   \n",
       "\n",
       "    num_misspelled  proportion_misspelled  \n",
       "0               12               0.061538  \n",
       "1                3               0.015306  \n",
       "2               15               0.090909  \n",
       "3                3               0.011407  \n",
       "4                4               0.028986  \n",
       "5                1               0.010870  \n",
       "6                3               0.051724  \n",
       "7                0               0.000000  \n",
       "8               22               0.095652  \n",
       "9                2               0.036364  \n",
       "10               0               0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)\n",
    "df.to_csv('../data_clean/spellcheck_requests_sample_statistics.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 0\n",
      " misspelled_list: ['cuantificados', 'sa-018tqa001-n231', '6)solicito', 'vigesima', '04/e25/2013', 'session', 'caas', 'aassp', 'realizacion', 'fraccion', 'comesa', 'adjucacion']\n",
      "Text: 1\n",
      " misspelled_list: ['medidos', 'descentralizados', 'fundamentan']\n",
      "Text: 2\n",
      " misspelled_list: ['no.', '2300-a001', '05/06/98', 'ct011', '20/06/2000', '1.-', 'institucionales', 'normativos', 'realizacion', 'planeacion', 'actualizacion', 'sustantivas', '2.-', 'deroga', 'emision']\n",
      "Text: 3\n",
      " misspelled_list: ['expide', 'consumibles', 'mensualizado']\n",
      "Text: 4\n",
      " misspelled_list: ['tuxpan', 'solicitadas', 'solicitad', '¿']\n",
      "Text: 5\n",
      " misspelled_list: ['ifai']\n",
      "Text: 6\n",
      " misspelled_list: ['09dpr1936a', 'cct', 'escutia']\n",
      "Text: 7\n",
      " misspelled_list: []\n",
      "Text: 8\n",
      " misspelled_list: ['revocacion', 'elaboracion', 'inicadas', 'imposicion', 'promovio', 'alude', 'inciadas', 'tubieron', 'derivaron', 'dictamenes', 'decomisos', 'originadas', 'originados', 'conseciones', 'clausuras', 'ascendio', 'recaudados', '¿', 'contensioso', 'peritajes', 'sancion', 'lgeepa']\n",
      "Text: 9\n",
      " misspelled_list: ['dependendecnia', 'apf']\n",
      "Text: 10\n",
      " misspelled_list: []\n"
     ]
    }
   ],
   "source": [
    "for i,misspelled_list in enumerate(df['misspelled']): \n",
    "    print(\"Text: {}\\n misspelled_list: {}\".format(i, misspelled_list)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are these actually mispelled?  \n",
    "\n",
    "The above table displays the number of words the spellchecker thought were misspelled, but are they actually? For this part and as a native Spanish speaker, I verified by hand and update the numbers of those that were actually misspelled. Note dates in certain formats and codes are usually detected as misspelled. I did not consider as false positives words that were detected as misspelled because they lack the stress mark. I calculated the precision metric based on the number of tokens of each text. However note the number of tokens in each text is also different. \n",
    "\n",
    "$$Precision = \\left( \\frac{TP}{TP + FP} \\right)$$\n",
    "\n",
    "**NOTE:** \n",
    "- The spellchecker does seem to detect lack of stress marks where they should be. \n",
    "\n",
    "The following are the false positives for each of the texts above: \n",
    "\n",
    "**Text 0** \n",
    "\n",
    "\"False positives:\" \n",
    "['cuantificados'] \n",
    "\n",
    "Precision: **0.96**\n",
    "\n",
    "\n",
    "**Text 1** \n",
    "\n",
    "\"False positives:\" \n",
    "['medidos', 'descentralizados', 'fundamentan']\n",
    "\n",
    "Precision: **0.00**\n",
    "\n",
    "**Text 2** \n",
    "\n",
    "\"False positives:\" \n",
    "['no.','05/06/98', '20/06/2000', '1.-', 'institucionales', 'normativos','sustantivas', 'emision'] **Note the dates**\n",
    "\n",
    "Precision: **0.46**\n",
    "\n",
    "**Text 3** \n",
    "\n",
    "\"False positives:\" \n",
    "['expide', 'consumibles', 'mensualizado']\n",
    "\n",
    "Precision: **0.00**\n",
    "\n",
    "**Text 4** \n",
    "\n",
    "\"False positives:\" \n",
    "['tuxpan', 'solicitadas', '¿'] **Note the interrogation mark. Is tuxpan the name of a place? **\n",
    "\n",
    "Precision: **0.46**\n",
    "\n",
    "**Text 5** \n",
    "\n",
    "\"False positives:\" \n",
    "[]\n",
    "\n",
    "Precision: **1.00**\n",
    "\n",
    "**Text 6** \n",
    "\n",
    "\"False positives:\" \n",
    "['09dpr1936a', 'cct', 'escutia'] **Note the codes are detected as misspelled**\n",
    "\n",
    "Precision: **0**\n",
    "\n",
    "**Text 7** \n",
    "\n",
    "\"False positives:\" \n",
    "[]\n",
    "\n",
    "Precision: **1**\n",
    "\n",
    "**Text 8** \n",
    "\n",
    "\"False positives:\" \n",
    " ['alude', 'tubieron', 'derivaron', decomisos', 'originadas', 'originados', 'conseciones', 'clausuras', 'ascendio', 'recaudados', '¿', 'contensioso', 'peritajes']\n",
    "\n",
    "Precision: **0.41**\n",
    "\n",
    "\n",
    "**Text 9** \n",
    "\n",
    "\"False positives:\" \n",
    "[]\n",
    "\n",
    "Precision: **1.0**\n",
    "\n",
    "**Text 10** \n",
    "\n",
    "\"False positives:\" \n",
    "[]\n",
    "\n",
    "Precision: **1.0**\n",
    "\n",
    "\n",
    "**NOTE:**: These precision calculations are not really indicative unless we also consider the proportion \"misspelled\" tokens in the text. \n",
    "\n",
    "\n",
    "### Veredict \n",
    "\n",
    "The spellchecker overall does a good job, but one should be specially aware of: \n",
    "- numbers, dates and codes (usually detected as misspelled)\n",
    "- lack of stress marks are detected as misspelled \n",
    "- besides this the rate of false positives doesn't seem to be too high, but does happen every once in a while. \n",
    "- Capitalization is irrelevant\n",
    "- The intial '¿' is detected as misspelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
